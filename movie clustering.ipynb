{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = file.drop(['Unnamed: 0', 'Unnamed: 0.1', 'genres', 'keywords', 'original_language', 'overview',\n",
    "                  'production_companies', 'production_countries', 'release_date', 'spoken_languages', 'tagline', 'title'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = file.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "file = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15095</th>\n",
       "      <th>15096</th>\n",
       "      <th>15097</th>\n",
       "      <th>15098</th>\n",
       "      <th>15099</th>\n",
       "      <th>15100</th>\n",
       "      <th>15101</th>\n",
       "      <th>15102</th>\n",
       "      <th>15103</th>\n",
       "      <th>15104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.623684</td>\n",
       "      <td>0.171815</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.479290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.858057</td>\n",
       "      <td>0.404040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.158846</td>\n",
       "      <td>0.344696</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.327225</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.122635</td>\n",
       "      <td>0.315884</td>\n",
       "      <td>0.437870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.324753</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.128272</td>\n",
       "      <td>0.389151</td>\n",
       "      <td>0.488166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.662158</td>\n",
       "      <td>0.434343</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.050169</td>\n",
       "      <td>0.101916</td>\n",
       "      <td>0.390533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.154450</td>\n",
       "      <td>0.434343</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 15105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3      4      5         6         7      \\\n",
       "0  0.623684  0.171815  1.000000  0.479290    0.0   0.72  0.858057  0.404040   \n",
       "1  0.789474  0.158846  0.344696  0.500000    0.0   0.69  0.327225  0.383838   \n",
       "2  0.644737  0.122635  0.315884  0.437870    0.0   0.63  0.324753  0.464646   \n",
       "3  0.657895  0.128272  0.389151  0.488166    0.0   0.76  0.662158  0.434343   \n",
       "4  0.684211  0.050169  0.101916  0.390533    0.0   0.61  0.154450  0.434343   \n",
       "\n",
       "      8         9      ...    15095  15096  15097  15098  15099  15100  15101  \\\n",
       "0  1.000000  0.300000  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1  0.363636  0.600000  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2  0.818182  0.833333  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3  0.545455  0.500000  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4  0.181818  0.200000  ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   15102  15103  15104  \n",
       "0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 15105 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = file.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = file.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_avg(data, length):\n",
    "    '''\n",
    "    @params data The file that containes all the data that needs to be clustered.\n",
    "    Their dimensions are expected to be larger than 2.\n",
    "    @return new_center The center of all the points\n",
    "    '''\n",
    "    dimensions = length\n",
    "    \n",
    "    new_center = []\n",
    "    \n",
    "    for d in range(dimensions):\n",
    "        dim_sum = 0 # sum of dimensions\n",
    "        for p in data:\n",
    "            dim_sum += p[d]\n",
    "            \n",
    "        new_center.append(dim_sum / float(len(data)))\n",
    "        \n",
    "    return new_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_centers(data, assignments):\n",
    "#     new_means = defaultdict(list)\n",
    "    centers = []\n",
    "#     for assignment, point in zip(assignments, data):\n",
    "#         new_means[assignment].append(point)\n",
    "        \n",
    "    for points in data:\n",
    "        centers.append(point_avg(points, len(points)))\n",
    "        \n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_points(data_points, centers):\n",
    "    assignments = []\n",
    "    for point in data_points:\n",
    "        shortest = 20000\n",
    "        shortest_index = 0\n",
    "        for i in range(len(centers)):\n",
    "            val = distance(point, centers[i])\n",
    "            if val < shortest:\n",
    "                shortest = val\n",
    "                shortest_index = i\n",
    "        assignments.append(shortest_index)\n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(a,b):\n",
    "    dimensions = len(a)\n",
    "    _sum = 0\n",
    "    for d in range(dimensions):\n",
    "        difference_sq = pow(a[d] - b[d], 2)\n",
    "        _sum += difference_sq\n",
    "    return sqrt(_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_k_points(data, k):\n",
    "    centers = []\n",
    "    \n",
    "    dimensions = len(data[0])\n",
    "    min_max = defaultdict(int)\n",
    "    \n",
    "    for point in data:\n",
    "        for i in range(dimensions):\n",
    "            val = point[i]\n",
    "            min_key = 'min_' + str(i)\n",
    "            max_key = 'max_' + str(i)\n",
    "            if min_key not in min_max or val < min_max[min_key]:\n",
    "                min_max[min_key] = val\n",
    "            if max_key not in min_max or val > min_max[max_key]:\n",
    "                min_max[max_key] = val\n",
    "                \n",
    "    for j in range(k):\n",
    "        rand_point = []\n",
    "        for i in range(dimensions):\n",
    "            min_val = min_max['min_' + str(i)]\n",
    "            max_val = min_max['max_' + str(i)]\n",
    "            \n",
    "            rand_point.append(uniform(min_val, max_val))\n",
    "        centers.append(rand_point)\n",
    "        \n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(data, k):\n",
    "    k_points = generate_k_points(data, k)\n",
    "    assignments = assign_points(data, k_points)\n",
    "    old_assignments = None\n",
    "    while assignments != old_assignments:\n",
    "        new_centers = update_centers(data, assignments)\n",
    "        old_assignments = assignments\n",
    "        assignments = assign_point(data, new_centers)\n",
    "    return zip(assignments, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-85fba6ce79d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_means\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-41507808d023>\u001b[0m in \u001b[0;36mk_means\u001b[1;34m(data, k)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mold_assignments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0massignments\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mold_assignments\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mnew_centers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_centers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0massignments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mold_assignments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massignments\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0massignments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_centers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-79-3bf5223d4770>\u001b[0m in \u001b[0;36mupdate_centers\u001b[1;34m(data, assignments)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpoints\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mcenters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint_avg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcenters\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-38e207de5980>\u001b[0m in \u001b[0;36mpoint_avg\u001b[1;34m(data, length)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mdim_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;31m# sum of dimensions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mdim_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mnew_center\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim_sum\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from random import uniform\n",
    "from math import sqrt\n",
    "\n",
    "points = [[1,2], [2,3], [3, 4], [4,5]]\n",
    "print(k_means(points, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansBase(object):\n",
    "\n",
    "    def __init__(self, n_clusters = 8, init = \"random\", max_iter = 300, random_state = None, n_init = 10, tol = 1e-4):\n",
    "        self.k = n_clusters # 聚类个数\n",
    "        self.init = init # 输出化方式\n",
    "        self.max_iter = max_iter # 最大迭代次数\n",
    "        self.random_state = check_random_state(random_state) #随机数\n",
    "        self.n_init = n_init # 进行多次聚类，选择最好的一次\n",
    "        self.tol = tol # 停止聚类的阈值\n",
    "\n",
    "    # fit对train建立模型\n",
    "    def fit(self, dataset):\n",
    "        self.tol = self._tolerance(dataset, self.tol)\n",
    "\n",
    "        bestError = None\n",
    "        bestCenters = None\n",
    "        bestLabels = None\n",
    "        for i in range(self.n_init):\n",
    "            labels, centers, error = self._kmeans(dataset)\n",
    "            if bestError == None or error < bestError:\n",
    "                bestError = error\n",
    "                bestCenters = centers\n",
    "                bestLabels = labels\n",
    "        self.centers = bestCenters\n",
    "        return bestLabels, bestCenters, bestError\n",
    "\n",
    "    # predict根据训练好的模型预测新的数据\n",
    "    def predict(self, X):\n",
    "        return self.update_labels_error(X, self.centers)[0]\n",
    "\n",
    "    # 合并fit和predict\n",
    "    def fit_predict(self, dataset):\n",
    "        self.fit(dataset)\n",
    "        return self.predict(dataset)\n",
    "\n",
    "    # kmeans的主要方法，完成一次聚类的过程\n",
    "    def _kmeans(self, dataset):\n",
    "        self.dataset = np.array(dataset)\n",
    "        bestError = None\n",
    "        bestCenters = None\n",
    "        bestLabels = None\n",
    "        centerShiftTotal = 0\n",
    "        centers = self._init_centroids(dataset)\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            oldCenters = centers.copy()\n",
    "            labels, error = self.update_labels_error(dataset, centers)\n",
    "            centers = self.update_centers(dataset, labels)\n",
    "\n",
    "            if bestError == None or error < bestError:\n",
    "                bestLabels = labels.copy()\n",
    "                bestCenters = centers.copy()\n",
    "                bestError = error\n",
    "\n",
    "            ## oldCenters和centers的偏移量\n",
    "            centerShiftTotal = np.linalg.norm(oldCenters - centers) ** 2\n",
    "            if centerShiftTotal <= self.tol:\n",
    "                break\n",
    "\n",
    "        #由于上面的循环，最后一步更新了centers，所以如果和旧的centers不一样的话，再更新一次labels，error\n",
    "        if centerShiftTotal > 0:\n",
    "            bestLabels, bestError = self.update_labels_error(dataset, bestCenters)\n",
    "\n",
    "        return bestLabels, bestCenters, bestError\n",
    "\n",
    "\n",
    "    # k个数据点，随机生成\n",
    "    def _init_centroids(self, dataset):\n",
    "        n_samples = dataset.shape[0]\n",
    "        centers = []\n",
    "        if self.init == \"random\":\n",
    "            seeds = self.random_state.permutation(n_samples)[:self.k]\n",
    "            centers = dataset[seeds]\n",
    "        elif self.init == \"k-means++\":\n",
    "            pass\n",
    "        return np.array(centers)\n",
    "\n",
    "\n",
    "    # 把tol和dataset相关联\n",
    "    def _tolerance(self, dataset, tol):\n",
    "        variances = np.var(dataset, axis=0)\n",
    "        return np.mean(variances) * tol\n",
    "\n",
    "\n",
    "    # 更新每个点的标签，和计算误差\n",
    "    def update_labels_error(self, dataset, centers):\n",
    "        labels = self.assign_points(dataset, centers)\n",
    "        new_means = defaultdict(list)\n",
    "        error = 0\n",
    "        for assignment, point in zip(labels, dataset):\n",
    "            new_means[assignment].append(point)\n",
    "\n",
    "        for points in new_means.values():\n",
    "            newCenter = np.mean(points, axis=0)\n",
    "            error += np.sqrt(np.sum(np.square(points - newCenter)))\n",
    "\n",
    "        return labels, error\n",
    "\n",
    "    # 更新中心点\n",
    "    def update_centers(self, dataset, labels):\n",
    "        new_means = defaultdict(list)\n",
    "        centers = []\n",
    "        for assignment, point in zip(labels, dataset):\n",
    "            new_means[assignment].append(point)\n",
    "\n",
    "        for points in new_means.values():\n",
    "            newCenter = np.mean(points, axis=0)\n",
    "            centers.append(newCenter)\n",
    "\n",
    "        return np.array(centers)\n",
    "\n",
    "\n",
    "    # 分配每个点到最近的center\n",
    "    def assign_points(self, dataset, centers):\n",
    "        labels = []\n",
    "        for point in dataset:\n",
    "            shortest = float(\"inf\")  # 正无穷\n",
    "            shortest_index = 0\n",
    "            for i in range(len(centers)):\n",
    "                val = distance(point[np.newaxis], centers[i])\n",
    "                if val < shortest:\n",
    "                    shortest = val\n",
    "                    shortest_index = i\n",
    "            labels.append(shortest_index)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import KMeansBase\n",
    "# from kmeans_plus import KMeansPlusPlus\n",
    "import time\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import datasets\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# from utils.misc_utils import distance, sortLabel\n",
    "# from kmeans.kmeans_base import KMeansBase\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_random_state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-b9bae697e6cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtsne\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pca'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mX_tsne\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeansBase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mtakeTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstartTime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dataset=%s model=%s takeTime=%s\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtakeTime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-284b4a3fd2d0>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_clusters, init, max_iter, random_state, n_init, tol)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit\u001b[0m \u001b[1;31m# 输出化方式\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[1;31m# 最大迭代次数\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#随机数\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_init\u001b[0m \u001b[1;31m# 进行多次聚类，选择最好的一次\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtol\u001b[0m \u001b[1;31m# 停止聚类的阈值\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'check_random_state' is not defined"
     ]
    }
   ],
   "source": [
    "allData = {\"iris\":datasets.load_iris().data, \"boston\":datasets.load_boston().data, \"digits\":datasets.load_digits().data}\n",
    "\n",
    "for dataName, value in allData.items():\n",
    "    n_clusters = 3\n",
    "    init = \"random\"\n",
    "    if dataName == \"digits\":\n",
    "        n_clusters = 10\n",
    "    #降维\n",
    "    tsne = TSNE(n_components=2, init='pca', random_state=0)\n",
    "    X_tsne = tsne.fit_transform(value)\n",
    "    labels = KMeansBase(n_clusters = n_clusters, init = init).fit_predict(value)\n",
    "    takeTime = time.time() - startTime\n",
    "    print(\"dataset=%s model=%s takeTime=%s\"%(dataName, modelName, round(takeTime, 5)))\n",
    "    plt.scatter(X_tsne[:, 0],X_tsne[:, 1], c=labels)\n",
    "    plt.show()\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def init(data, k):\n",
    "    data = list(data)\n",
    "    return random.sample(data, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_dis(data, centroid_list):\n",
    "    cluster_dict = dict()\n",
    "    \n",
    "    for item in data:\n",
    "        p1 = item\n",
    "        flag = -1\n",
    "        min_dis = float(\"inf\")\n",
    "        \n",
    "        for i in range(len(centroid_list)):\n",
    "            p2 = centroid_list[i]\n",
    "            dis = calc_dis(p1, p2)\n",
    "            if dis < min_dis:\n",
    "                flag = i\n",
    "                \n",
    "        if flag not in cluster_dict.keys():\n",
    "            cluster_dict.setdefault(flag, [])\n",
    "        cluster_dict[flag].append(item)\n",
    "        \n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dis(data, centroid_list):\n",
    "    clusterDict = dict()  \n",
    "    k = len(centroid_list)\n",
    "    for item in data:\n",
    "        p1 = item\n",
    "        flag = -1\n",
    "        minDis = float(\"inf\")  \n",
    "        for i in range(k):\n",
    "            p2 = centroid_list[i]\n",
    "            dis = calc_dis(p1, p2)  \n",
    "            if dis < minDis:\n",
    "                minDis = dis\n",
    "                flag = i  \n",
    "        if flag not in clusterDict.keys():\n",
    "            clusterDict.setdefault(flag, [])\n",
    "        clusterDict[flag].append(item)  \n",
    "    return clusterDict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids(cluster_dict):\n",
    "    import numpy as np\n",
    "    centroid_list = []\n",
    "    for key in cluster_dict.keys():\n",
    "        centroid = np.mean(cluster_dict[key])\n",
    "        centroid_list.append(centroid)\n",
    "    # 得到新的质心的集合\n",
    "    return centroid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_var(centroid_list, cluster_dict):\n",
    "    # 将族类中各个向量与质心的距离累加求和\n",
    "    sum = 0\n",
    "    for k in centroid_list.keys():\n",
    "        p1 = centroid_list[k]\n",
    "        dis = 0\n",
    "        for item in cluster_dict[k]:\n",
    "            p2 = item\n",
    "            dis += calc_dis(p1, p2)\n",
    "        sum += dis\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    data = file\n",
    "\n",
    "    centroid_list = init(data, 50)\n",
    "    cluster_dict = min_dis(data, centroid_list)\n",
    "\n",
    "    new_var = get_var(centroid_list, cluster_dict)\n",
    "    old_var = 1 \n",
    "\n",
    "    time = 2\n",
    "\n",
    "    while abs(new_var - old_var) >= 0.00001:\n",
    "        centroid_list = get_centroids(cluster_dict)\n",
    "        cluster_dict = min(data, centroid_list)\n",
    "        old_var = new_var\n",
    "        new_var = get_var(centroid_list, cluster_dict)\n",
    "        time += 1\n",
    "\n",
    "        show_cluster(centroid_list, cluster_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded in comparison",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-f84a9353dc55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-5d9fd3ddb6e9>\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcentroid_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mcluster_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_dis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcentroid_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnew_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_var\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentroid_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcluster_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-88d86b373a20>\u001b[0m in \u001b[0;36mmin_dis\u001b[1;34m(data, centroid_list)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentroid_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcentroid_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mdis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_dis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdis\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmin_dis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-74eaa6eb651f>\u001b[0m in \u001b[0;36mcalc_dis\u001b[1;34m(data, centroid_list)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcentroid_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mdis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_dis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdis\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mminDis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mminDis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdis\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "... last 1 frames repeated, from the frame below ...\n",
      "\u001b[1;32m<ipython-input-10-74eaa6eb651f>\u001b[0m in \u001b[0;36mcalc_dis\u001b[1;34m(data, centroid_list)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcentroid_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mdis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_dis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdis\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mminDis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mminDis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdis\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded in comparison"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(2147483647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "type(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "sequence too large; cannot be greater than 32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2e03e8b56a63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: sequence too large; cannot be greater than 32"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.ndarray(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = pd.read_csv('H:\\Downloads\\movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('H:\\Downloads\\movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4803 entries, 0 to 4802\n",
      "Data columns (total 20 columns):\n",
      "budget                  4803 non-null int64\n",
      "genres                  4803 non-null object\n",
      "homepage                1712 non-null object\n",
      "id                      4803 non-null int64\n",
      "keywords                4803 non-null object\n",
      "original_language       4803 non-null object\n",
      "original_title          4803 non-null object\n",
      "overview                4800 non-null object\n",
      "popularity              4803 non-null float64\n",
      "production_companies    4803 non-null object\n",
      "production_countries    4803 non-null object\n",
      "release_date            4802 non-null object\n",
      "revenue                 4803 non-null int64\n",
      "runtime                 4801 non-null float64\n",
      "spoken_languages        4803 non-null object\n",
      "status                  4803 non-null object\n",
      "tagline                 3959 non-null object\n",
      "title                   4803 non-null object\n",
      "vote_average            4803 non-null float64\n",
      "vote_count              4803 non-null int64\n",
      "dtypes: float64(3), int64(4), object(13)\n",
      "memory usage: 750.5+ KB\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
